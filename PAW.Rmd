---
title: "Pracsical Machine Learning Prediction Assignment Writeup"
author: "Vladimir Stepanov"
date: "26 декабря 2015 г."
output: html_document
---

Data from the Human Activity Recognition project ([http://groupware.les.inf.puc-rio.br/har](http://groupware.les.inf.puc-rio.br/har)) is used to build a model for predicting the quality of performing the exercise (the `classe` variable from the dataset). We build a random forest model which shows about 99% predictive accuracy.

## Data processing

We use `caret` and `randomForest` packages and set the seed for reproducibility. While loading the data we  treat strings as appropriate types (not factors). We also skip the first 7 columns as not relevant (they contain supplementary info and are not related to measurements).

```{r preload,cache=TRUE,results='hide',warning=FALSE,message=FALSE,tidy=TRUE}
library(caret)
library(randomForest)
set.seed(12345)
data_training <- read.csv("pml-training.csv", stringsAsFactors = FALSE)
data_testing <- read.csv("pml-testing.csv", stringsAsFactors = FALSE)
skip <- c(1, 2, 3, 4, 5, 6, 7)
data_training <- data_training[,-skip]
data_testing <- data_testing[,-skip]
```

After loading the data we exclude all fields (columns) that contain NAs or missing values. We do that for the test set — the one containing 20 test cases for submission — as fields that are not present there could not aid to their prediction.

In the end, we pick up only necessary fields from both testing and training data sets. Then we split the training set 75/25 — for model training and for cross-validation respectively. We also not the position of the `classe` field in the training set.

```{r cleanup,cache=TRUE,results='hide',warning=FALSE,message=FALSE,tidy=TRUE}
# cleaning the testing set:
# excluding columns with NAs
notNAs <- (apply(data_testing, 2, function(x) { sum(is.na(x)) } ) == 0)
data_testing <- data_testing[,notNAs]
# excluding columns with empty values
notEVs <- (apply(data_testing, 2, function(x) { sum(x == "") } ) == 0)
data_testing <- data_testing[,notEVs]
# we only need columns presented in the testing set
# (test set does not contain the classe variable)
data_training <- data_training[,
                               names(data_training) %in%
                                 c(names(data_testing), "classe")]

# we have checked the data_training set for NAs and empty cells
# (there were none)

# creating the training and cross-vadidation sets
inTrain <- createDataPartition(y=data_training$classe, p=0.75, list=FALSE)
training <- data_training[inTrain, ]
testing <- data_training[-inTrain, ]

# current position of the classe variable
keyVPos <- dim(data_training)[2]
```

## Modelling

For modelling we employ the `randomForest` package. We build the confusion matrix and record the prediction for our 20 test cases in the `answers` data set.

As seen from the accuracy, we expect the out of sample error to be around 1%.

```{r modelling,cache=TRUE,tidy=TRUE}
modelFit <- randomForest(y = as.factor(training$classe),
                         x = training[,-keyVPos])
answers <- predict(modelFit, data_testing)
confusionMatrix(testing$classe, predict(modelFit, testing))
```

```{r helpers,echo=FALSE,results='hide'}
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}
```
testing <- data_training[-inTrain, ]
# columns to skip: user name, timestamps, windows and classe
skip <- c(2, 3, 4, 5, 6, 7, 160)
# create preprocess object
preProc <- preProcess(training[,-skip], method="pca", pcaComp=2)
# calculate PCs for training data
trainPC <- predict(preProc, training[,-skip])
# run model on outcome and principle components
modelFit <- train(training$classe ~ ., method="glm", data=trainPC)
# calculate PCs for test data
testPC <- predict(preProc, testing[,-skip])
# compare results
confusionMatrix(testing$classe, predict(modelFit, testPC))
# create preprocess object
preProc <- preProcess(training[,-skip], method="pca")#, pcaComp=2)
# calculate PCs for training data
trainPC <- predict(preProc, training[,-skip])
# run model on outcome and principle components
modelFit <- train(training$classe ~ ., method="glm", data=trainPC)
# calculate PCs for test data
testPC <- predict(preProc, testing[,-skip])
# compare results
confusionMatrix(testing$classe, predict(modelFit, testPC))
preProc <- preProcess(training[,-skip], method="pca", thresh=0.95)#, pcaComp=2)
trainPC <- predict(preProc, training[,-skip])
modelFit <- train(training$classe ~ ., method="glm", data=trainPC)
pp<-preProcess(training[,-160],method="pca",pcaComp=2,thresh=0.95))
pp<-preProcess(training[,-160],method="pca",pcaComp=2,thresh=0.95)
pp
preProc
modelFit <- train(training$classe ~ ., method="gbm", data=trainPC)
warnings()
modelFit <- train(training$classe ~ ., method = "glm", preProcess = "pca", data = training)
# create preprocess object
preProc <- preProcess(log10(training[,-skip]+1), method="pca", thresh=0.95)#, pcaComp=2)
# calculate PCs for training data
trainPC <- predict(preProc, log10(training[,-skip]+1))
# run model on outcome and principle components
modelFit <- train(training$classe ~ ., method="gbm", data=trainPC)
rm(list=ls())
library(caret)
set.seed(12345)
data_training <- read.csv("pml-training.csv")
data_testing <- read.csv("pml-testing.csv")
inTrain <- createDataPartition(y=data_training$classe, p=0.75, list=FALSE)
training <- data_training[inTrain, ]
testing <- data_training[-inTrain, ]
# columns to skip: user name, timestamps, windows and classe
skip <- c(2, 3, 4, 5, 6, 7, 160)
# create preprocess object
preProc <- preProcess(log10(training[,-skip]+1), method="pca", thresh=0.95)#, pcaComp=2)
# calculate PCs for training data
trainPC <- predict(preProc, log10(training[,-skip]+1))
# run model on outcome and principle components
modelFit <- train(training$classe ~ ., method="glm", data=trainPC)
# calculate PCs for test data
testPC <- predict(preProc, log10(testing[,-skip]+1))
# compare results
confusionMatrix(testing$classe, predict(modelFit, testPC))
library(caret)
set.seed(12345)
data_training <- read.csv("pml-training.csv")
data_testing <- read.csv("pml-testing.csv")
inTrain <- createDataPartition(y=data_training$classe, p=0.75, list=FALSE)
training <- data_training[inTrain, ]
testing <- data_training[-inTrain, ]
skip <- c(2, 3, 4, 5, 6, 7, 160)
modelFit <- train(training$classe ~ ., method="glm", data=training)
is.na(training)
is.nan(training)
is.nan(training)
sapply(training, is.na)
lapply(training, is.na)
?apply
apply(training, 2, is.na)
summary(training)
apply(training, 2, function(x) { sum(is.na(x)) } )
apply(training, 2, function(x) { sum(is.na(x)) } ) > 0
apply(training, 2, function(x) { sum(is.na(x)) } ) == 0
names(apply(training, 2, function(x) { sum(is.na(x)) } ) == 0)
kk <- names(apply(training, 2, function(x) { sum(is.na(x)) } ) == 0)
training[,kk]
names(apply(training, 2, function(x) { sum(is.na(x)) } ))
apply(training, 2, function(x) { sum(is.na(x)) } == 0
)
apply(training, 2, function(x) { sum(is.na(x)) }) == 0
kk <- apply(training, 2, function(x) { sum(is.na(x)) }) == 0)
kk <- (apply(training, 2, function(x) { sum(is.na(x)) }) == 0)
kk
dim(training)
dim(training[,kk])
sum(kk == TRUE)
sum(kk == АФДЫУ)
sum(kk == FALSE)
rm(list=ls())
library(caret)
set.seed(12345)
data_training <- read.csv("pml-training.csv", stringsAsFactors = FALSE)
data_testing <- read.csv("pml-testing.csv", stringsAsFactors = FALSE)
# columns to skip: user name, timestamps, windows and classe
skip <- c(2, 3, 4, 5, 6, 7, 160)
data_training <- data_training[,-skip]
data_testing <- data_testing[,-skip]
# excluding columns with NAs
NAs <- (apply(training, 2, function(x) { sum(is.na(x)) } ) == 0)
data_training <- data_training[,-NAs]
data_testing <- data_testing[,-NAs]
rm(list=ls())
library(caret)
set.seed(12345)
data_training <- read.csv("pml-training.csv", stringsAsFactors = FALSE)
data_testing <- read.csv("pml-testing.csv", stringsAsFactors = FALSE)
# columns to skip: user name, timestamps, windows and classe
skip <- c(2, 3, 4, 5, 6, 7, 160)
data_training <- data_training[,-skip]
data_testing <- data_testing[,-skip]
# excluding columns with NAs
NAs <- (apply(data_training, 2, function(x) { sum(is.na(x)) } ) == 0)
data_training <- data_training[,-NAs]
data_testing <- data_testing[,-NAs]
rm(list=ls())
library(caret)
set.seed(12345)
data_training <- read.csv("pml-training.csv", stringsAsFactors = FALSE)
data_testing <- read.csv("pml-testing.csv", stringsAsFactors = FALSE)
# columns to skip: user name, timestamps, windows
# classe is a 160th column — keeping it for now
skip <- c(2, 3, 4, 5, 6, 7)
data_training <- data_training[,-skip]
data_testing <- data_testing[,-skip]
# excluding columns with NAs
NAs <- (apply(data_training, 2, function(x) { sum(is.na(x)) } ) == 0)
data_training <- data_training[,-NAs]
data_testing <- data_testing[,-NAs]
inTrain <- createDataPartition(y=data_training$classe, p=0.75, list=FALSE)
training <- data_training[inTrain, ]
testing <- data_training[-inTrain, ]
preProc <- preProcess(log10(training[,-160]+1), method="pca", thresh=0.95)#, pcaComp=2)
preProc <- preProcess(log10(training[,-160]+1), method="pca", thresh=0.95)#, pcaComp=2)
training[,-160]
is.na(testing)
sum(is.na(testing))
rm(list=ls())
library(caret)
set.seed(12345)
data_training <- read.csv("pml-training.csv", stringsAsFactors = FALSE)
data_testing <- read.csv("pml-testing.csv", stringsAsFactors = FALSE)
# columns to skip: user name, timestamps, windows
# classe is a 160th column — keeping it for now
skip <- c(2, 3, 4, 5, 6, 7)
data_training <- data_training[,-skip]
data_testing <- data_testing[,-skip]
# excluding columns with NAs
notNAs <- (apply(data_training, 2, function(x) { sum(is.na(x)) } ) == 0)
data_training <- data_training[,notNAs]
data_testing <- data_testing[,notNAs]
inTrain <- createDataPartition(y=data_training$classe, p=0.75, list=FALSE)
training <- data_training[inTrain, ]
testing <- data_training[-inTrain, ]
sum(is.na(testing))
sum(is.na(training))
dim(training)
dim(testing)
preProc <- preProcess(log10(training[,-160]+1), method="pca", thresh=0.95)#, pcaComp=2)
log10(training[,-160]+1)
training[,-160]
# create preprocess object
preProc <- preProcess(log10(training[,-87]+1), method="pca", thresh=0.95)#, pcaComp=2)
# calculate PCs for training data
trainPC <- predict(preProc, log10(training[,-87]+1))
# run model on outcome and principle components
modelFit <- train(training$classe ~ ., method="glm", data=trainPC)
# calculate PCs for test data
testPC <- predict(preProc, log10(testing[,-87]+1))
# compare results
confusionMatrix(testing$classe, predict(modelFit, testPC))
training[,-160]
preProc <- preProcess(log10(training[,-87]+1), method="pca", thresh=0.95)#, pcaComp=2)
training[,-87]
log10(training[,-87]+1)
log10(as.numeric(training[,-87])+1)
plot(training)
qqplot(training)
training == ""
sum(training == "")
rm(list=ls())
library(caret)
set.seed(12345)
data_training <- read.csv("pml-training.csv", stringsAsFactors = FALSE)
data_testing <- read.csv("pml-testing.csv", stringsAsFactors = FALSE)
# columns to skip: user name, timestamps, windows
skip <- c(2, 3, 4, 5, 6, 7)
data_training <- data_training[,-skip]
data_testing <- data_testing[,-skip]
# excluding columns with NAs
notNAs <- (apply(data_training, 2, function(x) { sum(is.na(x)) } ) == 0)
data_training <- data_training[,notNAs]
data_testing <- data_testing[,notNAs]
# excluding columns with empty values
notEVs <- (apply(data_training, 2, function(x) { sum(x == "") } ) == 0)
data_training <- data_training[,notEVs]
data_testing <- data_testing[,notEVs]
dim(testInheritedMethods())
dim(data_testing)
dim(data_training)
dim(data_training)[2]
kk <- dim(data_training)[2]
data_training[,-kk]
data_training
data_training[,-kk]
dim(data_training[,-kk])
dim(data_training)
ls()
rm(list=ls())
library(caret)
set.seed(12345)
data_training <- read.csv("pml-training.csv", stringsAsFactors = FALSE)
data_testing <- read.csv("pml-testing.csv", stringsAsFactors = FALSE)
# columns to skip: user name, timestamps, windows
skip <- c(2, 3, 4, 5, 6, 7)
data_training <- data_training[,-skip]
data_testing <- data_testing[,-skip]
# excluding columns with NAs
notNAs <- (apply(data_training, 2, function(x) { sum(is.na(x)) } ) == 0)
data_training <- data_training[,notNAs]
data_testing <- data_testing[,notNAs]
# excluding columns with empty values
notEVs <- (apply(data_training, 2, function(x) { sum(x == "") } ) == 0)
data_training <- data_training[,notEVs]
data_testing <- data_testing[,notEVs]
inTrain <- createDataPartition(y=data_training$classe, p=0.75, list=FALSE)
training <- data_training[inTrain, ]
testing <- data_training[-inTrain, ]
# current position of the classe variable
keyVPos <- dim(data_training)[2]
# create preprocess object
preProc <- preProcess(log10(training[,-keyVPos]+1), method="pca", thresh=0.95)#, pcaComp=2)
# calculate PCs for training data
trainPC <- predict(preProc, log10(training[,-keyVPos]+1))
# run model on outcome and principle components
modelFit <- train(training$classe ~ ., method="glm", data=trainPC)
# calculate PCs for test data
testPC <- predict(preProc, log10(testing[,-keyVPos]+1))
# compare results
confusionMatrix(testing$classe, predict(modelFit, testPC))
pp <- preProcess(training, method="pca", thresh=0.95)
pp
preProc <- preProcess(training, method="pca", thresh=0.95)
# create preprocess object
preProc <- preProcess(training, method="pca", thresh=0.95)
# calculate PCs for training data
trainPC <- predict(preProc, training)
# run model on outcome and principle components
modelFit <- train(training$classe ~ ., method="glm", data=trainPC)
# calculate PCs for test data
testPC <- predict(preProc, testing)
# compare results
confusionMatrix(testing$classe, predict(modelFit, testPC))
# create preprocess object
preProc <- preProcess(training[,-keyVPos], method="pca", thresh=0.95)
# calculate PCs for training data
trainPC <- predict(preProc, training[,-keyVPos])
# run model on outcome and principle components
modelFit <- train(training$classe ~ ., method="glm", data=trainPC)
# calculate PCs for test data
testPC <- predict(preProc, testing[,-keyVPos])
# compare results
confusionMatrix(testing$classe, predict(modelFit, testPC))
View(training)
View(training)
is.na(training)
sum(is.na(training))
sum(is.na(testing))
preProc <- preProcess(training[,-keyVPos], method="pca", thresh=0.95)
trainPC <- predict(preProc, training[,-keyVPos])
modelFit <- train(training$classe ~ ., method="rf", data=trainPC)
install.packages("randomForest")
library(randomForest)
modelFit <- train(training$classe ~ ., method="rf", data=trainPC)
modelFit <- randomForest(x = training$classe, y = training[,-keyVPos])
modelFit <- randomForest(y = training$classe, x = training[,-keyVPos])
modelFit <- randomForest(y = as.factor(training$classe), x = training[,-keyVPos])
?train
modelFit <- train(y = training$classe, x = training[,-keyVPos], method="rf", data=trainPC)
modelFit <- train(y = training$classe, x = training[,-keyVPos], method="rf")
modelFit <- train(y = as.factor(training$classe), x = training[,-keyVPos], method="rf")
modelFit <- randomForest(y = as.factor(training$classe),
x = training[,-keyVPos])
confusionMatrix(testing$classe, predict(modelFit, testing[,-keyVPos]))
1395 + 949 + 855 + 804 +  901
dim(testing)
predict(modelFit, data_testing[,-keyVPos])
View(data_testing)
notNAs <- (apply(data_testing, 2, function(x) { sum(is.na(x)) } ) == 0)
notNAs
rm(list=ls())
library(caret)
library(randomForest)
set.seed(12345)
data_training <- read.csv("pml-training.csv", stringsAsFactors = FALSE)
data_testing <- read.csv("pml-testing.csv", stringsAsFactors = FALSE)
names(data_training)[c(2, 3, 4, 5, 6, 7)]
names(data_testing)[c(2, 3, 4, 5, 6, 7)]
notNAs <- (apply(data_testing, 2, function(x) { sum(is.na(x)) } ) == 0)
# cleaning the testing set:
# excluding columns with NAs
notNAs <- (apply(data_testing, 2, function(x) { sum(is.na(x)) } ) == 0)
data_testing <- data_testing[,notNAs]
# excluding columns with empty values
notEVs <- (apply(data_testing, 2, function(x) { sum(x == "") } ) == 0)
data_testing <- data_testing[,notEVs]
data_training <- data_training[,names(data_testing)]
names(data_testing)
rm(list=ls())
library(caret)
library(randomForest)
set.seed(12345)
data_training <- read.csv("pml-training.csv", stringsAsFactors = FALSE)
data_testing <- read.csv("pml-testing.csv", stringsAsFactors = FALSE)
names(data_testing)
# columns to skip: user name, timestamps, windows
skip <- c(2, 3, 4, 5, 6, 7)
data_training <- data_training[,-skip]
data_testing <- data_testing[,-skip]
names(data_testing)
notNAs <- (apply(data_testing, 2, function(x) { sum(is.na(x)) } ) == 0)
dim(data_testing)
data_testing <- data_testing[,notNAs]
dim(data_testing)
notEVs <- (apply(data_testing, 2, function(x) { sum(x == "") } ) == 0)
data_testing <- data_testing[,notEVs]
notEVs <- (apply(data_testing, 2, function(x) { sum(x == "") } ) == 0)
dim(data_testing)
data_training <- data_training[,c(names(data_testing))]
class(notNAs)
names(data_testing)
class(names(data_testing))
c(names(data_testing))
class(c(names(data_testing)))
data_training <- data_training[,c(names(data_testing))]
data_training[,c("accel_forearm_y", "accel_forearm_z")]
data_training[c(names(data_testing))]
data_training[c(names(data_testing)),]
data_training[c(names(data_testing))]
data_training[names(data_testing)]
names(data_testing)
data_training[names(data_testing),]
data_training[,names(data_testing)]
notEVs
dim(notEVs)
length(notEVs)
dim(data_testing)
class(notEVs)
notEVs[1]
notEVs[2]
names(data_testing)
names(data_testing) = TRUE
names(data_testing)
rm(list=ls())
ibrary(caret)
library(randomForest)
set.seed(12345)
data_training <- read.csv("pml-training.csv", stringsAsFactors = FALSE)
data_testing <- read.csv("pml-testing.csv", stringsAsFactors = FALSE)
# columns to skip: user name, timestamps, windows
skip <- c(2, 3, 4, 5, 6, 7)
data_training <- data_training[,-skip]
data_testing <- data_testing[,-skip]
# cleaning the testing set:
# excluding columns with NAs
notNAs <- (apply(data_testing, 2, function(x) { sum(is.na(x)) } ) == 0)
data_testing <- data_testing[,notNAs]
# excluding columns with empty values
notEVs <- (apply(data_testing, 2, function(x) { sum(x == "") } ) == 0)
data_testing <- data_testing[,notEVs]
as.vector(names(data_testing))
data_training[as.vector(names(data_testing))]
data_training[c(names(data_testing))]
data_training[c("gyros_arm_x", "gyros_arm_y", "gyros_arm_z")]
class(c("gyros_arm_x", "gyros_arm_y", "gyros_arm_z"))
class(names(data_testing))
data_training[c(as.character(names(data_testing)))]
data_training[c(as.vector(names(data_testing)))]
data_training[, names(data_training) %in% names(data_testing)]
dim(data_training[, names(data_training) %in% names(data_testing)])
data_training <- data_training[,
names(data_training) %in% names(data_testing)]
sum(is.na(data_training))
inTrain <- createDataPartition(y=data_training$classe, p=0.75, list=FALSE)
training <- data_training[inTrain, ]
testing <- data_training[-inTrain, ]
# current position of the classe variable
keyVPos <- dim(data_training)[2]
modelFit <- randomForest(y = as.factor(training$classe),
x = training[,-keyVPos])
confusionMatrix(testing$classe, predict(modelFit, testing))
inTrain <- createDataPartition(y=data_training$classe, p=0.75, list=FALSE)
dim(data_training)
names(data_training)
rm(list=ls())
library(caret)
library(randomForest)
set.seed(12345)
data_training <- read.csv("pml-training.csv", stringsAsFactors = FALSE)
data_testing <- read.csv("pml-testing.csv", stringsAsFactors = FALSE)
# columns to skip: user name, timestamps, windows
skip <- c(2, 3, 4, 5, 6, 7)
data_training <- data_training[,-skip]
data_testing <- data_testing[,-skip]
# cleaning the testing set:
# excluding columns with NAs
notNAs <- (apply(data_testing, 2, function(x) { sum(is.na(x)) } ) == 0)
data_testing <- data_testing[,notNAs]
# excluding columns with empty values
notEVs <- (apply(data_testing, 2, function(x) { sum(x == "") } ) == 0)
data_testing <- data_testing[,notEVs]
# we only need columns presented in the testing set
data_training <- data_training[,
names(data_training) %in%
c(names(data_testing), "classe")]
inTrain <- createDataPartition(y=data_training$classe, p=0.75, list=FALSE)
training <- data_training[inTrain, ]
testing <- data_training[-inTrain, ]
# current position of the classe variable
keyVPos <- dim(data_training)[2]
modelFit <- randomForest(y = as.factor(training$classe),
x = training[,-keyVPos])
confusionMatrix(testing$classe, predict(modelFit, testing))
predict(modelFit, data_testing)
rm(list=ls())
library(caret)
library(randomForest)
set.seed(12345)
data_training <- read.csv("pml-training.csv", stringsAsFactors = FALSE)
data_testing <- read.csv("pml-testing.csv", stringsAsFactors = FALSE)
# columns to skip: user name, timestamps, windows
skip <- c(2, 3, 4, 5, 6, 7)
data_training <- data_training[,-skip]
data_testing <- data_testing[,-skip]
# cleaning the testing set:
# excluding columns with NAs
notNAs <- (apply(data_testing, 2, function(x) { sum(is.na(x)) } ) == 0)
data_testing <- data_testing[,notNAs]
# excluding columns with empty values
notEVs <- (apply(data_testing, 2, function(x) { sum(x == "") } ) == 0)
data_testing <- data_testing[,notEVs]
# we only need columns presented in the testing set
# (test set does not contain the classe variable)
data_training <- data_training[,
names(data_training) %in%
c(names(data_testing), "classe")]
# we may check data_training for NAs and empty cells — there are none
# creating the training and cross-vadidation sets
inTrain <- createDataPartition(y=data_training$classe, p=0.60, list=FALSE)
training <- data_training[inTrain, ]
testing <- data_training[-inTrain, ]
# current position of the classe variable
keyVPos <- dim(data_training)[2]
modelFit <- randomForest(y = as.factor(training$classe),
x = training[,-keyVPos])
confusionMatrix(testing$classe, predict(modelFit, testing))
predict(modelFit, data_testing)
rm(list=ls())
library(caret)
library(randomForest)
set.seed(12345)
data_training <- read.csv("pml-training.csv", stringsAsFactors = FALSE)
data_testing <- read.csv("pml-testing.csv", stringsAsFactors = FALSE)
# columns to skip: user name, timestamps, windows
skip <- c(1, 2, 3, 4, 5, 6, 7)
data_training <- data_training[,-skip]
data_testing <- data_testing[,-skip]
# cleaning the testing set:
# excluding columns with NAs
notNAs <- (apply(data_testing, 2, function(x) { sum(is.na(x)) } ) == 0)
data_testing <- data_testing[,notNAs]
# excluding columns with empty values
notEVs <- (apply(data_testing, 2, function(x) { sum(x == "") } ) == 0)
data_testing <- data_testing[,notEVs]
# we only need columns presented in the testing set
# (test set does not contain the classe variable)
data_training <- data_training[,
names(data_training) %in%
c(names(data_testing), "classe")]
# we may check data_training for NAs and empty cells — there are none
# creating the training and cross-vadidation sets
inTrain <- createDataPartition(y=data_training$classe, p=0.60, list=FALSE)
training <- data_training[inTrain, ]
testing <- data_training[-inTrain, ]
# current position of the classe variable
keyVPos <- dim(data_training)[2]
modelFit <- randomForest(y = as.factor(training$classe),
x = training[,-keyVPos])
confusionMatrix(testing$classe, predict(modelFit, testing))
predict(modelFit, data_testing)
answers <- predict(modelFit, data_testing)
answers
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(answers)
summary(modelFit)
modelFit$err.rate
qplot(modelFit)
plot(modelFit)
ls()
rm(list=ls())
ls()
